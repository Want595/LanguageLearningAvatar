# 魔珐星云具身智能黑客松 - 《Language Learning Avatar 》项目创意书

## 一、 基本信息

**项目名称：** Language Learning Avatar (具身智能口语陪练)
**参赛赛道：** 教育
**团队名称：** Want595
**一句话介绍：** 基于魔珐星云的多语言口语陪练助手，通过具身智能数字人提供沉浸式、有情感的实时外语对话练习体验。

## 二、 项目背景与痛点

**解决什么问题？**
1.  **缺乏语言环境**：语言学习者通常缺乏真实的口语交流环境，导致“哑巴外语”现象。
2.  **真人陪练成本高**：聘请母语私教费用昂贵，且时间难以灵活协调。
3.  **交互体验单一**：传统的文字聊天机器人或纯语音助手缺乏视觉反馈（面部表情、肢体语言），无法模拟真实的人际交往体验。

**目标用户是谁？**
*   K12 学生及大学生（需应对口语考试）。
*   职场人士（商务英语/多语言沟通需求）。
*   语言爱好者（希望低成本保持语感）。

**核心解决方案：**
利用具身智能技术，构建一位永远在线、耐心且富有表现力的 3D 数字人外教。用户可以像面对真人一样与其进行语音对话，数字人不仅能用纯正的语音回答，还能通过面部表情和肢体动作给予情感反馈（如点头鼓励、微笑示意），从而降低用户的开口焦虑，提升学习沉浸感。

## 三、 产品核心功能

**功能点 1：多语言实时语音对话**
*   支持 7 种语言（英、中、日、韩、法、德、西）的自由切换。
*   集成低延迟 ASR（自动语音识别）与 LLM（大语言模型），实现流畅的自然语言问答，模拟真实的对话节奏。

**功能点 2：具身智能情感交互**
*   数字人具备丰富的情感表现力。根据对话内容的情感色彩（如鼓励、解释、闲聊），数字人会自动匹配相应的面部表情和肢体动作（如在用户回答正确时点头微笑，在思考时做出倾听姿态）。
*   视觉反馈弥补了纯语音交流的枯燥感，增强了人机连接。

**功能点 3：智能纠错与翻译辅助**
*   **翻译模式**：当用户遇到表达困难时，可请求数字人进行翻译，辅助理解。
*   **角色扮演**：针对不同语言设定特定的 System Prompt，使数字人保持“耐心导师”的人设，引导用户多开口。

## 四、 技术架构与实现

**技术栈规划：**
*   **前端/终端**：Web (Vue 3 + Vite + TypeScript)
    *   负责 UI 交互、音频采集与播放。
    *   集成魔珐星云 SDK 进行 3D 数字人渲染与驱动。
*   **后端服务**：Python (Flask)
    *   处理业务逻辑，转发 ASR/TTS 请求（如需）。
    *   管理 LLM 对话上下文。
*   **大模型选用**：Qwen (通义千问 Qwen3-235B-Instruct)
    *   通过 ModelScope 接口调用，提供强大的多语言理解与生成能力。
*   **ASR/TTS**：
    *   ASR：集成腾讯云 ASR 或同类实时语音识别服务。
    *   TTS/Avatar驱动：通过魔珐星云 API/SDK 实现文本驱动数字人发音与口型同步。

**魔珐星云集成方案：**
计划在 Web 前端通过 SDK 加载 3D 数字人模型。
1.  **初始化**：在 `AvatarRender.vue` 中初始化魔珐 SDK，加载预设形象。
2.  **交互循环**：
    *   用户语音 -> ASR 转文本 -> 发送至后端。
    *   后端调用 LLM 生成回复文本。
    *   前端接收文本 -> 调用魔珐 SDK 的 TTS/驱动接口 -> 数字人播报并做动作。
3.  **动作控制**：根据 LLM 返回的情感标签（未来规划）或语义分析，触发 SDK 内置的特定动作库。

**架构草图：**
```
[用户] <-> [浏览器 (Vue3 + 魔珐 SDK)]
                 |       ^
             (Audio/Text)|
                 v       |
           [Python Flask 后端]
                 |       ^
                 v       |
          [LLM Service (Qwen)]
```

## 五、 资源需求评估

**预计 LLM 调用量级：**
*   高频交互，由于是实时对话应用，每次对话轮次较多，预计开发测试期间每日不少于 100 次调用，比赛演示期间可能更高。

**其他特殊需求：**
*   无
